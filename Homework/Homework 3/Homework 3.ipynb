{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recitation Problems - Chapter 5\n",
    "\n",
    "## Exercise 2 - Support & Confidence\n",
    "\n",
    "### a. Compute the support for itemsets {e}, {b,d}, and {b,d,e} by treating each transaction ID as a market basket. Note: 10 transaction in total. \n",
    "\n",
    "Support Count for {e} = # of transactions containing e = 8\n",
    "\n",
    "**Support for {e}** = Support count/ total transactions = ($\\frac{8}{10}$) = **0.8**\n",
    "\n",
    "Support Count for {b,d} = # of transactions containing b & d = 2\n",
    "\n",
    "**Support for {b,d} = ** = ($\\frac{2}{10}$) = **0.2**\n",
    "\n",
    "Support Count for {b,d,e} = # of transactions containing b, d, & e = 2\n",
    "\n",
    "**Support for {b,d,e}** = ($\\frac{2}{10}$) = **0.2**\n",
    "\n",
    "### b. Use results from (a) to compute confidence for association rules {b,d} --> {e} and {e} --> {b,d}. Is confidence a symmetric measure?\n",
    "\n",
    "**Confidence for {b,d} --> {e}** = Support for {b,d,e} / Support for {b,d} = ($\\frac{0.2}{0.2}$) = **1**\n",
    "\n",
    "**Confidence for {e} --> {b,d}** = Support for {b,d,e} / Support for {e} = ($\\frac{0.2}{0.8}$) = **0.25**\n",
    "\n",
    "Based on the above, **confidence is not a symmetric measure**.\n",
    "\n",
    "### c. Repeat (a) by treating Customer ID as a market basket. Note: 5 total transactions\n",
    "\n",
    "Support Count for {e} = # of transactions containing e = 4\n",
    "\n",
    "**Support for {e}** = Support count/ total transactions = ($\\frac{4}{5}$) = **0.8**\n",
    "\n",
    "Support Count for {b,d} = # of transactions containing b & d = 5\n",
    "\n",
    "**Support for {b,d}** = ($\\frac{5}{5}$) = **1**\n",
    "\n",
    "Support Count for {b,d,e} = # of transactions containing b, d, & e = 4\n",
    "\n",
    "**Support for {b,d,e}** = ($\\frac{4}{5}$) = **0.8**\n",
    "\n",
    "### d. Use results from (c) to repeat (b). \n",
    "\n",
    "**Confidence for {b,d} --> {e}** = Support for {b,d,e} / Support for {b,d} = ($\\frac{0.8}{1}$) = **0.8**\n",
    "\n",
    "**Confidence for {e} --> {b,d}** = Support for {b,d,e} / Support for {e} = ($\\frac{0.8}{0.8}$) = **1**\n",
    "\n",
    "### e. Suppose $s_1$ and $c_1$ are support and confidence values for rule *r* when treating Transaction ID as a market basket and $s_2$ and $c_2$ are support and confidence values for rule *r* when treating Customer ID as a market basket. Discuss whether there is a relationship between $s_1$ & $s_2$ or $c_1$ & $c_2$.\n",
    "\n",
    "I do not think there is any significant relationship between either of two. The only thing that remains equal among the two is that the support for {e} is 0.8. Everything else is different. \n",
    "\n",
    "## Exercise 6 - Frequent Itemset Generation/Rule Generation\n",
    "\n",
    "### a. What is the maximum # of association rules that can be extracted from Table 5.21 (including minsup > 0)?\n",
    "\n",
    "Total # of association rules = $3^d$ - $2^{d+1} $ + 1 = $3^6$ - $2^7$ + 1 = **602 rules**\n",
    "\n",
    "### b. What is the max size of frequent itemsets that can be extracted (minsup > 0)?\n",
    "\n",
    "Since the largest itemset shown in the table is 4, then **4 is the max size**.\n",
    "\n",
    "### c. Write an expression for the max # of size-3 itemsets that can be derived from this dataset. \n",
    "\n",
    "$\\binom{n}{k}$ = $\\binom{6}{3}$ = 20\n",
    "\n",
    "### d. Find an itemset (2+) that has the largest support.\n",
    "\n",
    "Items: Milk, Beer, Diapers, Bread, Butter, and Cookies. Note: Support for {Milk, Butter} = {Butter, Milk} so removing repeated calculations saves time.\n",
    "__________________\n",
    "\n",
    "Support for {Milk, Beer} = ($\\frac{1}{10}$) = 0.1\n",
    "\n",
    "Support for {Milk, Diapers} = ($\\frac{3}{10}$) = 0.3\n",
    "\n",
    "Support for {Milk, Bread} = ($\\frac{2}{10}$) = 0.2\n",
    "\n",
    "Support for {Milk, Butter} = ($\\frac{2}{10}$) = 0.2\n",
    "\n",
    "Support for {Milk, Cookies} = ($\\frac{1}{10}$) = 0.1\n",
    "__________________\n",
    "Support for {Beer, Diapers} = ($\\frac{3}{10}$) = 0.3\n",
    "\n",
    "Support for {Beer, Bread} = 0\n",
    "\n",
    "Support for {Beer, Butter} = 0\n",
    "\n",
    "Support for {Beer, Cookies} = ($\\frac{2}{10}$) = 0.2\n",
    "__________________\n",
    "Support for {Diapers, Bread} = ($\\frac{3}{10}$) = 0.3\n",
    "\n",
    "Support for {Diapers, Butter} = ($\\frac{3}{10}$) = 0.3\n",
    "\n",
    "Support for {Diapers, Cookies} = ($\\frac{2}{10}$) = 0.2\n",
    "__________________\n",
    "Support for {Bread, Butter} =  ($\\frac{5}{10}$) = 0.5\n",
    "\n",
    "Support for {Bread, Cookies} = ($\\frac{1}{10}$) = 0.1\n",
    "__________________\n",
    "Support for {Butter, Cookies} = ($\\frac{1}{10}$) = 0.1\n",
    "\n",
    "**{Bread, Butter}** has the largest support count.\n",
    "\n",
    "### e. Find a pair of items, *a* & *b*, such that the rules {a}  --> {b} & {b} --> {a} have the same confidence.\n",
    "\n",
    "Since I have all the support calculated for all pairs, I just need to calculate all the confidence for all rules.\n",
    "\n",
    "Support {Milk} = 0.5; Support {Beer} = 0.4; Support {Diapers} = 0.6; Support {Bread} = 0.5; Support {Butter} = 0.5; Support {Cookies} = 0.4\n",
    "__________________\n",
    "Confidence for {Milk} --> {Beer} = Support for {Milk, Beer} / Support for {Milk} = ($\\frac{0.1}{0.5}$) = 0.2\n",
    "\n",
    "Confidence for {Beer} --> {Milk} = Support for {Milk, Beer} / Support for {Beer} = ($\\frac{0.1}{0.4}$) = 0.25\n",
    "__________________\n",
    "Confidence for {Milk} --> {Diapers} = Support for {Milk, Diapers} / Support for {Milk} = ($\\frac{0.3}{0.5}$) = 0.6\n",
    "\n",
    "Confidence for {Diapers} --> {Milk} = Support for {Milk, Diapers} / Support for {Diapers} = ($\\frac{0.3}{0.6}$) = 0.5\n",
    "__________________\n",
    "Confidence for {Milk} --> {Bread} = Support for {Milk, Bread} / Support for {Milk} = ($\\frac{0.2}{0.5}$) = 0.4\n",
    "\n",
    "Confidence for {Bread} --> {Milk} = Support for {Milk, Bread} / Support for {Bread} = ($\\frac{0.2}{0.5}$) = 0.4\n",
    "\n",
    "Since it says find *a pair*, I can stop here. **{Milk, Bread}**.\n",
    "\n",
    "## Exercise 8 - Candidate Generation\n",
    "\n",
    "Consider the following frequent 3-itemsets: \n",
    "\n",
    "{1,2,3}, {1,2,4}, {1,2,5}, {1,3,4}, {1,3,5}, {2,3,4}, {2,3,5}, {3,4,5}\n",
    "\n",
    "### a. List all candidate 4-itemsets obtained by a candidate generation procedure using the $F_{k-1}$ x $F_1$ merging strategy.\n",
    "\n",
    "From the list given above, the frequent 1-itemsets would then be {1}, {2}, {3}, {4}, & {5}. The book mentioned that a candicate generation procedure is *complete* if it does not omit a frequent itemset and it does not contain duplicates. To ensure no duplicate candidates are generated, we must make sure the items within each frequent itemset are sorted in their lexicographic order. Since, in our case, they are numbers it will be easy to verify order.\n",
    "\n",
    "Candidate Generation:\n",
    "1. {1,2,3} + {4} = {1,2,3,4}\n",
    "2. {1,2,3} + {5} = {1,2,3,5}\n",
    "3. {1,2,4} + {5} = {1,2,4,5}\n",
    "4. {1,3,4} + {5} = {1,3,4,5}\n",
    "5. {2,3,4} + {5} = {2,3,4,5} \n",
    "\n",
    "To understand what was accomplished above, a walk-through example is needed. For the first frequent 3-itemset, only two of the frequent 1-itemset could be added to generate a candidate since they contain items that are greater than the ones in the 3-itemset. That is why {1,2,3} is matched with {4} & {5}. \n",
    "\n",
    "The frequent 3-itemset {1,2,5} is skipped because it neither of the frequent 1-itemsets are greater than its current items. The biggest 1-itemset is {5}, but the 3-itemset already contains 5 in it. Same for {1,3,5}, {2,3,5} & {3,4,5}. \n",
    "\n",
    "Thus, the generated candidates are: **{1,2,3,4}, {1,2,3,5}, {1,2,4,5}, {1,3,4,5}, & {2,3,4,5}**\n",
    "\n",
    "### b. List all candidate 4-itemsets obtained by the candidate generation procedure used in the *Apriori*.\n",
    "\n",
    "The Apriori algorithm uses the $F_{k-1}$ x  $F_{k-1}$, which only merges a pair of frequent (k-1)-itemsets if their first k-2 items are identical (lexicographic order included). Since we are forming a 4-itemset, the first k-2 = 4-2 = 2 positions must be the same in order to merge.\n",
    "\n",
    "Candidate Generation Comparison:\n",
    "1. {1,2,3} vs {1,2,4} - The first 2 position are the same, thus we merge the two. {1,2,3,4}\n",
    "2. {1,2,3} vs {1,2,5} - The first 2 positions are the same, thus we merge. {1,2,3,5}\n",
    "3. {1,2,3} vs {1,3,4} - The first 2 positions are not the same, so no merge done.\n",
    "4. {1,2,3} vs {1,3,5} - No merge.\n",
    "5. {1,2,3} vs {2,3,4} - No merge\n",
    ".\n",
    "6. {1,2,4} vs {1,2,5} - Merge. {1,2,4,5}\n",
    ".\n",
    "7. {2,3,4} vs {2,3,5} - Merge. {2,3,4,5}\n",
    "\n",
    "Comparing this method to the previous shown in (a), only 4 candidates were generated instead of 5. These are **{1,2,3,4}, {1,2,3,5}, {1,2,4,5} & {2,3,4,5}**.\n",
    "\n",
    "\n",
    "### c.  List all candidate 4-itemsets that survive the candidate pruning step of the *Apriori* alg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

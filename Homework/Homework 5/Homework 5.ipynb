{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recitation Exercises\n",
    "\n",
    "## Exercise 7\n",
    "\n",
    "a) Find the limit of the value shown in the text for Grubbs' test as m approached infinity?\n",
    "\n",
    "$\\lim_{m \\to \\infty} \\frac{m-1}{\\sqrt{m}} \\sqrt{\\frac{t^2_C}{m-2+t^2_C}}$ = $\\lim_{m \\to \\infty} \\frac{m-1}{\\sqrt{m(m -2 + t^2_C)}} * t_C$ = 1 * $t_C$ = $t_C$\n",
    "\n",
    "b) Describe the meaning of the result above.\n",
    "\n",
    "I'm honestly unsure of the meaning. I can understand that the Grubbs test basically idenifies the maxiumum value from m as an outlier, but not really sure how limiting the value above proves this. From the algorithm, we can see that $t_C$ is chosen so that the probability of the sample mean is greater than equal to $t_C$ is equal to the significance level, which in this case is 0.05. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8\n",
    "\n",
    "Many statisical test for outliers were developed in an environment in which a few hundered observations was a large data set.\n",
    "\n",
    "a) For a set of 1,000,000 values, how likely are we to have outliers according to the test that says a value is an outlier if it is more than 3 standard deviations from the average?\n",
    "\n",
    "![bell-curve](bell-cuve.png)\n",
    "\n",
    "The image above is a normal bell-curve that shows up to three standard deviations from the mean. As shown above, 0.14% on each side of the bell-curve is considered as above three standard deviation. Because of this, you can say that 0.28% is more than 3 standard deviations. In our example with the 1,000,000 values, at least 280,000 would be outliers.\n",
    "\n",
    "b) Does the approach that states an outlier is an object of unusually low probability need to be adjusted when dealing with large data sets? If so, how?\n",
    "\n",
    "I feel like it depends on what the data set actually is. It's important to remember that outliers have a major influence of what is determined from the data. If the outliers are considered a negative influence, then you would try to minimize the amount of outliers present. If the outliers are the only thing that are considered interesting, then you would expect to see a little more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9\n",
    "\n",
    "The probability density of a point x w/ respect to a multivariate normal distribution having a mean $\\mu$ & a covariance matrix $\\Sigma$ is given by ... if we log f(x), then the following results in:\n",
    "\n",
    "log prob(x) = - log(($\\sqrt{2\\pi})^{m} *|\\Sigma|^{1/2}$ - $\\frac{1}{2}*(x-\\mu)*\\Sigma^{-1}*(x-\\mu)^{T}$\n",
    "\n",
    "If we use the sample mean and the covariance matrix as estimates of $\\mu$ & $\\Sigma$, then\n",
    "\n",
    "log prob(x) = - log(($\\sqrt{2\\pi})^{m} *|S|^{1/2}$ - $\\frac{1}{2}*(x-\\overline{x})*S^{-1}*(x-\\overline{x})^{T}$\n",
    "\n",
    "If you noticed that the left side represents a constant factor, then the right side wth the variables (sample mean) should be the closest to matching to the Mahalanobis distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 11\n",
    "\n",
    "Considere the K-means scheme for outlier detecion described in Sec 9.5 & Fig. 9.10.\n",
    "\n",
    "a) The pts. on the bottom of the compact cluster in Fig. 9.10 have a higher outlier score than those at the top of the compact cluster. Why?\n",
    "\n",
    "The mean of the points (pt. D) is pulled somewhat upward from the center of the compact cluster.\n",
    "\n",
    "b) Suppose that we choose the # of clusters to be larger (10). Would the proposed technique still be effective in finding the most extreme outlier at the top of the figure? Why or why not?\n",
    "\n",
    "In this case, the point would just become a cluster by itself, so the proposed technique would never work.\n",
    "\n",
    "c) Use of relative distance adjusts for differences in density. Provide an example of where the approach leads to a wrong conclusion.\n",
    "\n",
    "Anything within the health department might not lead to the correct conclusion. If, for example, if someone's heart rate is above or below a certain range, then it would not be a good idea to ignore such an outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 12\n",
    "\n",
    "If the probability that a normal object is classified as an anomaly is 0.01 & the probability that an anomalous object is classified as an anomalous is 0.99, then what is the false alarm rate and detection rate if 99% of the objects are normal?\n",
    " \n",
    "detection rate = # of anomalies detected/total # of anomalies = 99%.\n",
    "\n",
    "false rate = # of false anomalies/# of objects classified as anomalies = (0.99m * 0.01)/(0.99m * 0.01 + 0.01m * 0.99) = 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 16\n",
    "\n",
    "Consider a set of points that are uniformly distributed on the interval [0,1]. Is the statistical notion of an outlier as an infrequently observed value meaningful for this data?\n",
    "\n",
    "If the set of points are uniformly distributed then each object should have at least the same probability. The only way that an outlier would be meaningful if it had a low probability, which in this case, it doesn't. So, no."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
